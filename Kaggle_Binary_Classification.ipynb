{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c3cb1af-559b-4d9a-b720-6dcfe8ee5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b8bcc3-2db9-48f4-a312-231ee9b8d4ba",
   "metadata": {},
   "source": [
    "#  - submition one was made with a randomforest classifier no params, scored in the 29th percentile, not great\n",
    "#  - Second submition made with random forest tuned for the best hyperparams with a gridseach, better score, \n",
    "# - Thrid submition made with random forest, same tuning as for attempt 2 but with new features engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c9ff20-cd9d-4088-9838-c9b26e228542",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea57cc89-6175-4a25-8a66-cbe3b085f615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15674932</td>\n",
       "      <td>Okwudilichukwu</td>\n",
       "      <td>668</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15749177</td>\n",
       "      <td>Okwudiliolisa</td>\n",
       "      <td>627</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15694510</td>\n",
       "      <td>Hsueh</td>\n",
       "      <td>678</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15741417</td>\n",
       "      <td>Kao</td>\n",
       "      <td>581</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>148882.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84560.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15766172</td>\n",
       "      <td>Chiemenam</td>\n",
       "      <td>716</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15068.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  CustomerId         Surname  CreditScore Geography Gender   Age  Tenure  \\\n",
       "0   0    15674932  Okwudilichukwu          668    France   Male  33.0       3   \n",
       "1   1    15749177   Okwudiliolisa          627    France   Male  33.0       1   \n",
       "2   2    15694510           Hsueh          678    France   Male  40.0      10   \n",
       "3   3    15741417             Kao          581    France   Male  34.0       2   \n",
       "4   4    15766172       Chiemenam          716     Spain   Male  33.0       5   \n",
       "\n",
       "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0       0.00              2        1.0             0.0        181449.97   \n",
       "1       0.00              2        1.0             1.0         49503.50   \n",
       "2       0.00              2        1.0             0.0        184866.69   \n",
       "3  148882.54              1        1.0             1.0         84560.88   \n",
       "4       0.00              2        1.0             1.0         15068.83   \n",
       "\n",
       "   Exited  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52a730f3-ad96-4510-8997-bd23676007e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Exited', 'Surname'], axis=1)\n",
    "y = df['Exited'] \n",
    "\n",
    "testdf = pd.read_csv('test.csv') \n",
    "X_test = testdf.drop(['Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89df8d65-2883-4820-83d8-82fdbef2746d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;id&#x27;, &#x27;CustomerId&#x27;,\n",
       "                                                   &#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;,\n",
       "                                                   &#x27;UtilizationRate&#x27;,\n",
       "                                                   &#x27;Age_NumOfProducts&#x27;,\n",
       "                                                   &#x27;CreditScore_IsActive&#x27;,\n",
       "                                                   &#x27;Age_Squared&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 RandomForestClassifier(max_depth=10, n_estimators=200,\n",
       "                                        random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;id&#x27;, &#x27;CustomerId&#x27;,\n",
       "                                                   &#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;,\n",
       "                                                   &#x27;UtilizationRate&#x27;,\n",
       "                                                   &#x27;Age_NumOfProducts&#x27;,\n",
       "                                                   &#x27;CreditScore_IsActive&#x27;,\n",
       "                                                   &#x27;Age_Squared&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 RandomForestClassifier(max_depth=10, n_estimators=200,\n",
       "                                        random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;id&#x27;, &#x27;CustomerId&#x27;, &#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                  &#x27;Tenure&#x27;, &#x27;Balance&#x27;, &#x27;NumOfProducts&#x27;,\n",
       "                                  &#x27;HasCrCard&#x27;, &#x27;IsActiveMember&#x27;,\n",
       "                                  &#x27;EstimatedSalary&#x27;, &#x27;UtilizationRate&#x27;,\n",
       "                                  &#x27;Age_NumOfProducts&#x27;, &#x27;CreditScore_IsActive&#x27;,\n",
       "                                  &#x27;Age_Squared&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                 [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;id&#x27;, &#x27;CustomerId&#x27;, &#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Tenure&#x27;, &#x27;Balance&#x27;, &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;, &#x27;IsActiveMember&#x27;, &#x27;EstimatedSalary&#x27;, &#x27;UtilizationRate&#x27;, &#x27;Age_NumOfProducts&#x27;, &#x27;CreditScore_IsActive&#x27;, &#x27;Age_Squared&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Geography&#x27;, &#x27;Gender&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['id', 'CustomerId',\n",
       "                                                   'CreditScore', 'Age',\n",
       "                                                   'Tenure', 'Balance',\n",
       "                                                   'NumOfProducts', 'HasCrCard',\n",
       "                                                   'IsActiveMember',\n",
       "                                                   'EstimatedSalary',\n",
       "                                                   'UtilizationRate',\n",
       "                                                   'Age_NumOfProducts',\n",
       "                                                   'CreditScore_IsActive',\n",
       "                                                   'Age_Squared']),\n",
       "                                                 ('cat', OneHotEncoder(),\n",
       "                                                  ['Geography', 'Gender'])])),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(max_depth=10, n_estimators=200,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Defining categorical and numerical features\n",
    "categorical_features = ['Geography', 'Gender']\n",
    "numerical_features = X.drop(columns=categorical_features).columns.tolist()\n",
    "\n",
    "# Creating a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)])\n",
    "\n",
    "# Creating a pipeline with preprocessing and classifier\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', RandomForestClassifier(n_estimators=200, min_samples_split=2, max_depth=10, random_state=42))])\n",
    "\n",
    "\n",
    "# Training the model\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc9a7b11-699a-4838-ba25-fafac4d7f9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=100; total time=   8.3s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=100; total time=   8.3s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=100; total time=   8.5s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=100; total time=   8.4s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=100; total time=   8.4s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  16.8s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  17.3s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  17.1s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  16.7s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  16.5s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  25.0s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  24.9s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  25.0s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  25.0s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  25.2s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=100; total time=   8.8s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=100; total time=   8.6s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=100; total time=   8.4s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=100; total time=   8.6s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=100; total time=   8.6s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  17.4s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  17.0s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  16.6s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  16.7s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  16.7s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  25.9s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  24.9s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  25.0s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  25.2s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  25.2s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=100; total time=   8.5s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=100; total time=   8.4s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=100; total time=   8.4s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=100; total time=   8.4s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=100; total time=   8.4s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  16.7s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  17.4s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  17.3s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  16.7s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  16.8s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  25.0s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  25.2s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  24.9s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  25.0s\n",
      "[CV] END classifier__max_depth=10, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  25.3s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=100; total time=  13.6s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=100; total time=  13.6s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=100; total time=  13.6s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=100; total time=  13.7s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=100; total time=  13.5s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  26.9s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  27.0s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  27.5s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  27.1s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  27.0s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  40.3s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  40.5s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  40.5s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  41.7s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  40.4s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=100; total time=  13.5s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=100; total time=  13.8s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=100; total time=  14.0s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=100; total time=  13.8s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=100; total time=  13.4s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  26.8s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  26.8s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  27.0s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  26.7s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  26.5s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  40.1s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  40.5s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  40.4s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  40.1s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  40.0s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=100; total time=  13.1s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=100; total time=  13.3s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=100; total time=  13.2s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=100; total time=  13.1s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=100; total time=  13.2s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  26.2s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  26.5s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  26.2s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  26.3s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  26.4s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  39.4s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  39.4s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  39.1s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  38.9s\n",
      "[CV] END classifier__max_depth=20, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  39.1s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=100; total time=  14.2s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=100; total time=  14.2s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=100; total time=  14.2s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=100; total time=  14.4s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=100; total time=  14.5s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  28.2s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  28.4s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  28.3s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  28.3s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=200; total time=  29.0s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  42.5s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  42.5s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  42.7s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  42.6s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=2, classifier__n_estimators=300; total time=  42.9s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=100; total time=  14.0s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=100; total time=  14.1s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=100; total time=  14.0s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=100; total time=  14.0s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=100; total time=  14.1s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  27.9s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  28.1s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  28.2s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  28.3s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=200; total time=  28.2s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  41.9s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  42.5s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  42.2s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  43.3s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=5, classifier__n_estimators=300; total time=  42.3s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=100; total time=  13.8s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=100; total time=  13.8s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=100; total time=  13.7s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=100; total time=  13.8s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=100; total time=  14.0s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  27.5s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  27.8s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  27.4s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  27.6s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=200; total time=  27.8s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  41.7s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  41.4s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  41.1s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  41.5s\n",
      "[CV] END classifier__max_depth=30, classifier__min_samples_split=10, classifier__n_estimators=300; total time=  42.2s\n",
      "Best parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ead2646-f4a0-4825-9bd6-4e9fa234c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating some test and train tests to test the effectivness of other aproaches like random forsts and XGB boost \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_csv('train.csv') \n",
    "\n",
    "# feature enginnering \n",
    "df['UtilizationRate'] = df['Balance'] / (df['NumOfProducts'] + 1)\n",
    "df['Age_NumOfProducts'] = df['Age'] * df['NumOfProducts']\n",
    "df['CreditScore_IsActive'] = df['CreditScore'] * df['IsActiveMember']\n",
    "df['Age_Squared'] = df['Age'] ** 2\n",
    "\n",
    "\n",
    "X = df.drop(['Exited', 'Surname'], axis=1)\n",
    "y = df['Exited'] \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42) \n",
    "# making the new df the contest df for convienence with feature enginenering\n",
    "\n",
    "df = pd.read_csv('test.csv') \n",
    "\n",
    "df['UtilizationRate'] = df['Balance'] / (df['NumOfProducts'] + 1)\n",
    "df['Age_NumOfProducts'] = df['Age'] * df['NumOfProducts']\n",
    "df['CreditScore_IsActive'] = df['CreditScore'] * df['IsActiveMember']\n",
    "df['Age_Squared'] = df['Age'] ** 2\n",
    "\n",
    "X_contest = df.drop(['Surname'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba5dfcb1-b4be-45cc-aced-8f0a1d27db63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>UtilizationRate</th>\n",
       "      <th>Age_NumOfProducts</th>\n",
       "      <th>CreditScore_IsActive</th>\n",
       "      <th>Age_Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15674932</td>\n",
       "      <td>668</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1089.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15749177</td>\n",
       "      <td>627</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>1089.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15694510</td>\n",
       "      <td>678</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15741417</td>\n",
       "      <td>581</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>148882.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84560.88</td>\n",
       "      <td>74441.27</td>\n",
       "      <td>34.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>1156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15766172</td>\n",
       "      <td>716</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15068.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>1089.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  CustomerId  CreditScore Geography Gender   Age  Tenure    Balance  \\\n",
       "0   0    15674932          668    France   Male  33.0       3       0.00   \n",
       "1   1    15749177          627    France   Male  33.0       1       0.00   \n",
       "2   2    15694510          678    France   Male  40.0      10       0.00   \n",
       "3   3    15741417          581    France   Male  34.0       2  148882.54   \n",
       "4   4    15766172          716     Spain   Male  33.0       5       0.00   \n",
       "\n",
       "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  UtilizationRate  \\\n",
       "0              2        1.0             0.0        181449.97             0.00   \n",
       "1              2        1.0             1.0         49503.50             0.00   \n",
       "2              2        1.0             0.0        184866.69             0.00   \n",
       "3              1        1.0             1.0         84560.88         74441.27   \n",
       "4              2        1.0             1.0         15068.83             0.00   \n",
       "\n",
       "   Age_NumOfProducts  CreditScore_IsActive  Age_Squared  \n",
       "0               66.0                   0.0       1089.0  \n",
       "1               66.0                 627.0       1089.0  \n",
       "2               80.0                   0.0       1600.0  \n",
       "3               34.0                 581.0       1156.0  \n",
       "4               66.0                 716.0       1089.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb3c5d-7a01-4ce7-874e-200fe8b12898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize XGBClassifier\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "# Create a pipeline with preprocessing and the model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', xgb_model)])\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200, 300],\n",
    "    'classifier__max_depth': [2, 3, 5, 7],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# Use this pipeline in GridSearchCV with verbosity\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Now the best_model will be a pipeline\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "# Fit the best model with early stopping (manually)\n",
    "best_model = best_pipeline.named_steps['classifier']\n",
    "best_model.fit(best_pipeline.named_steps['preprocessor'].transform(X_train), y_train, \n",
    "               early_stopping_rounds=50, eval_set=[(best_pipeline.named_steps['preprocessor'].transform(X_val), y_val)], \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acafa963-4d42-406a-a7e6-fcaac4a99480",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown model type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m random_search\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Assuming X_train, y_train are your training data and labels\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m best_search \u001b[38;5;241m=\u001b[39m \u001b[43mfit_random_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_search\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m best_params \u001b[38;5;241m=\u001b[39m best_search\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[1;32m     36\u001b[0m best_score \u001b[38;5;241m=\u001b[39m best_search\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36mfit_random_search\u001b[0;34m(random_search, X, y)\u001b[0m\n\u001b[1;32m     25\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mset_params(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n\u001b[0;32m---> 28\u001b[0m random_search\u001b[38;5;241m.\u001b[39mestimator \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_assigner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m random_search\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m random_search\n",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36mfit_random_search.<locals>.model_assigner\u001b[0;34m(estimator, params)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_assigner\u001b[39m(estimator, params):\n\u001b[0;32m---> 24\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_picker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mset_params(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36mmodel_picker\u001b[0;34m(**params)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgbm__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m): v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgbm__\u001b[39m\u001b[38;5;124m'\u001b[39m)})\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown model type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown model type"
     ]
    }
   ],
   "source": [
    "# Ensure your ColumnTransformer is applied to the data\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline with preprocessing and the model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', xgb_model)])\n",
    "\n",
    "# Initialize XGBClassifier\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [350, 375, 400, 425, 450],\n",
    "    'classifier__max_depth': [3, 4, 5, 6],\n",
    "    'classifier__learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
    "    'classifier__min_child_weight': [1, 3, 5, 7],\n",
    "    'classifier__subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'classifier__colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'classifier__gamma': [0, 0.1, 0.2, 0.3, 0.4]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Use this pipeline in GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Now the best_model will be a pipeline\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "best_model = best_pipeline.named_steps['classifier']\n",
    "\n",
    "# Fit the best model with early stopping (using the pipeline)\n",
    "best_pipeline.fit(X_train, y_train, classifier__early_stopping_rounds=50, classifier__eval_set=[(X_val, y_val)], classifier__verbose=True)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = best_pipeline.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0cb6371-44e6-40db-8af3-c1bb9dfbd364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__subsample': 0.7, 'classifier__n_estimators': 420, 'classifier__min_child_weight': 5, 'classifier__max_depth': 6, 'classifier__learning_rate': 0.0125, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85dea2f1-8b57-4044-8de4-1da70d4e181f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:44:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"lgbm__bagging_fraction\", \"lgbm__bagging_freq\", \"lgbm__feature_fraction\", \"lgbm__learning_rate\", \"lgbm__max_depth\", \"lgbm__n_estimators\", \"lgbm__num_leaves\", \"model_type\", \"xgb__colsample_bytree\", \"xgb__learning_rate\", \"xgb__max_depth\", \"xgb__n_estimators\", \"xgb__subsample\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     60\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipeline,\n\u001b[1;32m     61\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# After fitting, access the best parameters and score\u001b[39;00m\n\u001b[1;32m     73\u001b[0m best_params \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1806\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1805\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1806\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1808\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1809\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 420\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1491\u001b[0m (\n\u001b[1;32m   1492\u001b[0m     model,\n\u001b[1;32m   1493\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1499\u001b[0m )\n\u001b[1;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1517\u001b[0m )\n\u001b[0;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     _check_call(\n\u001b[0;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2054\u001b[0m     )\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np \n",
    "\n",
    "categorical_features = ['Geography', 'Gender']\n",
    "numerical_features = X.drop(columns=categorical_features).columns\n",
    "\n",
    "# Preprocessor setup\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Pipeline setup with a placeholder for the model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBClassifier())  # Default model\n",
    "])\n",
    "\n",
    "# Example parameter grid for RandomizedSearchCV\n",
    "def model_picker(**params):\n",
    "    model_type = params.pop('model__model_type')\n",
    "    if model_type == 'xgb':\n",
    "        # Filter out only xgb parameters\n",
    "        xgb_params = {k.split(\"__\")[2]: v for k, v in params.items() if 'xgb__' in k}\n",
    "        return XGBClassifier(**xgb_params)\n",
    "    elif model_type == 'lgbm':\n",
    "        # Filter out only lgbm parameters\n",
    "        lgbm_params = {k.split(\"__\")[2]: v for k, v in params.items() if 'lgbm__' in k}\n",
    "        return LGBMClassifier(**lgbm_params)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type\")\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'model__model_type': ['xgb', 'lgbm'],\n",
    "    'model__xgb__n_estimators': [100, 200, 300],\n",
    "    'model__xgb__max_depth': [3, 6, 9],\n",
    "    'model__xgb__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__xgb__subsample': [0.5, 0.7, 1.0],\n",
    "    'model__xgb__colsample_bytree': [0.5, 0.7, 1.0],\n",
    "    'model__lgbm__n_estimators': [100, 200, 300],\n",
    "    'model__lgbm__max_depth': [3, 6, 9],\n",
    "    'model__lgbm__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__lgbm__num_leaves': [31, 62, 127],\n",
    "    'model__lgbm__feature_fraction': [0.5, 0.7, 1.0],\n",
    "    'model__lgbm__bagging_fraction': [0.5, 0.7, 1.0],\n",
    "    'model__lgbm__bagging_freq': [5, 7, 9]\n",
    "}\n",
    "\n",
    "\n",
    "# RandomizedSearchCV setup\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# After fitting, access the best parameters and score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538e357-1c94-4028-949c-1204b07f0064",
   "metadata": {},
   "source": [
    "# Most promising code setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89641919-22cd-4608-9a6c-a7d0ed0575b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating some test and train tests to test the effectivness of other aproaches like random forsts and XGB boost \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_csv('train.csv') \n",
    "\n",
    "# feature enginnering \n",
    "df['UtilizationRate'] = df['Balance'] / (df['NumOfProducts'])\n",
    "df['Age_NumOfProducts'] = df['Age'] * df['NumOfProducts']\n",
    "df['CreditScore_IsActive'] = df['CreditScore'] * df['IsActiveMember']\n",
    "df['Age_Squared'] = df['Age'] ** 2\n",
    "\n",
    "\n",
    "X = df.drop(['Exited', 'Surname'], axis=1)\n",
    "y = df['Exited'] \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42) \n",
    "# making the new df the contest df for convienence with feature enginenering\n",
    "\n",
    "df = pd.read_csv('test.csv') \n",
    "\n",
    "df['UtilizationRate'] = df['Balance'] / (df['NumOfProducts'])\n",
    "df['Age_NumOfProducts'] = df['Age'] * df['NumOfProducts']\n",
    "df['CreditScore_IsActive'] = df['CreditScore'] * df['IsActiveMember']\n",
    "df['Age_Squared'] = df['Age'] ** 2\n",
    "\n",
    "X_contest = df.drop(['Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9b0b15a-8781-4738-9fb9-e830c2f6d7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 50 candidates, totalling 400 fits\n",
      "Best parameters: {'classifier__subsample': 0.9, 'classifier__n_estimators': 400, 'classifier__min_child_weight': 4, 'classifier__max_depth': 6, 'classifier__max_bin': 200, 'classifier__learning_rate': 0.01, 'classifier__lambda': 0.1, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 1.0, 'classifier__alpha': 0.7000000000000001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np \n",
    "\n",
    "# Define your preprocessor\n",
    "categorical_features = ['Geography', 'Gender']\n",
    "numerical_features = X.drop(columns=categorical_features).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)])\n",
    "\n",
    "\n",
    "# Create a pipeline with preprocessing and the model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [350, 375, 400, 420, 425, 435],\n",
    "    'classifier__max_depth': [2, 4, 5, 6, 7, 8],\n",
    "    'classifier__learning_rate': [0.005, 0.01, 0.0125, 0.015, 0.0175, 0.0185, 0.02],\n",
    "    'classifier__max_bin': [200, 256, 400, 512, 1024], \n",
    "    'classifier__min_child_weight': [1, 2, 3, 4, 5],\n",
    "    'classifier__subsample': [0.6, 0.7, 0.75, 0.8, 0.9, 1.0],\n",
    "    'classifier__colsample_bytree': [0.6, 0.65, 0.7, 0.75, 0.8, 1.0],\n",
    "    'classifier__gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'classifier__alpha': np.linspace(0.1, 1, 10),  \n",
    "    'classifier__lambda': np.linspace(0.1, 1, 10)  \n",
    "}\n",
    "\n",
    "# Hyperparameter grid\n",
    "# param_grid = {\n",
    "#     'classifier__n_estimators': [200, 350, 375, 400, 420, 425, 435],\n",
    "#     'classifier__max_depth': [2, 4, 5, 6, 7, 8],\n",
    "#     'classifier__learning_rate': [0.005, 0.01, 0.0125, 0.015, 0.0175, 0.0185, 0.02],\n",
    "#     'max_bin': [256, 512, 1024],  \n",
    "#     'classifier__min_child_weight': [1, 2, 3, 4, 5],\n",
    "#     'classifier__subsample': [0.6, 0.7, 0.75, 0.8, 0.9, 1.0],\n",
    "#     'classifier__colsample_bytree': [0.6, 0.65, 0.7, 0.75, 0.8, 1.0],\n",
    "#     'classifier__gamma': [0, 0.05, 0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "# }\n",
    "\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = RandomizedSearchCV(pipeline, param_grid, n_iter=50, cv=8, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Best model pipeline\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d7a70e7-d3c2-4a39-8ea1-5dbac57f2fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__subsample': 0.7, 'classifier__n_estimators': 350, 'classifier__min_child_weight': 5, 'classifier__max_depth': 7, 'classifier__max_bin': 256, 'classifier__learning_rate': 0.015, 'classifier__lambda': 0.1, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 0.75, 'classifier__alpha': 0.7000000000000001}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eed137db-1246-4d65-a607-e774804a966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id    Exited\n",
      "0       165034  0.022393\n",
      "1       165035  0.816304\n",
      "2       165036  0.033736\n",
      "3       165037  0.245209\n",
      "4       165038  0.345200\n",
      "...        ...       ...\n",
      "110018  275052  0.047670\n",
      "110019  275053  0.102760\n",
      "110020  275054  0.022450\n",
      "110021  275055  0.155831\n",
      "110022  275056  0.204409\n",
      "\n",
      "[110023 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Generating predictions for the entire dataset\n",
    "predictions = best_pipeline.predict_proba(X_contest)[:, 1]\n",
    "\n",
    "# Create a DataFrame for output\n",
    "output = pd.DataFrame({'id': X_contest['id'], 'Exited': predictions})\n",
    "\n",
    "print(output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "829d1e01-5e9f-45e7-99a2-34cbb1f968ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04c8bf55-c97c-4a31-9f25-e4a6b82b8cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions for the entire dataset\n",
    "# predictions = model.predict_proba(X_contest)[:, 1]\n",
    "\n",
    "# # Create a DataFrame for output\n",
    "# output = pd.DataFrame({'id': X_contest['id'], 'Exited': predictions})\n",
    "\n",
    "# print(output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc85021-8522-4b09-b708-6cff5b673110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda88f14-7785-44fd-a48b-e65fe458182b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b598035-481e-4a72-9d55-b44641e6893b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a1025-3e22-44b0-b56c-02d008869601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
